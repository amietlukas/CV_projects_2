{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Torchvision contains convinience functions for popular datasets like MNIST\n",
    "ds_train = datasets.MNIST('data', train=True, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sample is a 28x28 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<PIL.Image.Image image mode=L size=28x28 at 0x105F0D820>, 5)\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAB4AHgBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiijrTvLf+435Vf0vRrrVpSkCHI9q3rf4d6xcsQidPasmPw1fSaudNVD5wOOldnafBLxLdwiVFXafasPXvh1q/h5WN3t+XrxXHkYOKKKKKciGRgq9TXb6J8Mda1uyFzbxEqfauv0b4N6grD7ZAce4rtLL4QWCzRmW3G3vxXXr8LfDAQKbIEgdauWHw/0DTnLW9qFJqTU7bSdCtTPIioDxzXAafP4Yj8QnUJAmSc5rrbr4k6DaR7IpV4HArw/4j+OU1m4dIpAVPpXk5OSTSUUUU+OQxuGHUV9Q/CTxTZL4cjtppFEnFekf2/p5nWETjzG6CtLPGe1cx4n8X2Hh4AXEoQn3rG0b4n6LdzGOW6UZ6c1z/xo8QR/8ItHJZS7t3cGvnX+373GN5/OoJNUuZTlnP51Ud2kbcxyabRRRRRWzpHiK60h1MLHA966PTfHmo3HiC2kZjjcB1r6h0PVp9S8PtcEfvFTivmv4rarqF7qWy6DKqtx7153BcSW8qyI5BBzwa29T8WX2qaallOcxr05rn6KKKKKKKKKntLg2l1HOoyUOa+kPhN47i1C0FpdOqMflwTVP41eEXu44rq0iLd/lFfP8umXkDESW7jHtVUgg4IwaSiiiiiiiiiitTQtVm0rU4J45GVVYEgGvqrwh4u0/wAXaYkF0YwyKB8x61Jqvw4sNQSRognzA4wK+ePGXgO50W+mZI2KbjjiuGdGjYqwwR2ptFFFFFFFFFFa2j6/e6Rco8M7qoOSAa948HfGOB44rW5+ZuASTXp2paRZeJ9IWVYkzIuQcV86/Eb4dTaEZb5R+7znAry2iiiiiiiiiip7a0lupAkaEk+1dhpHw91m6lilhyvzA19YeF7WWy8O2lvMcyImDXH/ABdvLOHwxIJlBPNfJ91Ikk7NGMKagoooooooqSGF55BHGpJNd14Y+GuqatMkhjPl554r3Xwz8L9OsY0a6t1349K7u20OwtFAihAxUOq+ILDQ4S1w4CgdjXg/xU+IGl69p8tnasC9eH0UUUUUVYsrKfULgQW6FnPQV12n/DLXrpgTbNg+1exeBvhLawW6yanBiUeor1fTtGtNKj22yBQPaoNT8S6dpKk3UwXHvXlfi/4vW8Ksum3A3exrxbW/H2s6yzrPMShPAzXKsxdizHJNJRRRRQOSBXovgj4ft4hmTzIiUavbfDnwf0vRrhbnaPMHavQEgtNOi3FVUAdcVDJr+mxRl3uVCjqa4Hxh8UtPsYHTT7pXcDsa+fvEHj3U9clcSudmTjmuTZi7FmJJPrSUUUUUUUA4INd94Z+KOoeGkVbeFW2jFdOf2g9b/wCfZf0rN1H43azqMZR49oPoa5q68faldWzwsWAbvmuUeWSRizOxJ9TTKKKKKKKKKKKKKKKKKKKKKKK//9k=",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=120x120>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If we index this dataset, we get a single data point: a PIL image and an Integer\n",
    "print(ds_train[0])\n",
    "ds_train[0][0].resize((120,120))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we pass samples from the dataset to our model, we would like to normalize the data and convert the samples to PyTorch tensors. We begin by computing the normalization constants, i.e. the mean and the standard deviation of the pixel values in the MNIST training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets get only the images \n",
    "ims_train = ds_train.data\n",
    "ims_train = ims_train.float() / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# TODO: calculate the mean and std of MNIST images\n",
    "# hint: to look for operations on pytorch tensor, refer to the official PyTorch docs \n",
    "# https://pytorch.org/docs/stable/\n",
    "#########################################################################\n",
    "mu = torch.mean(ims_train)\n",
    "std = torch.std(ims_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now redefine the train and test datasets with the transform operations that perform normalization and conversion to tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mu, std)\n",
    "])\n",
    "ds_train = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "ds_test = datasets.MNIST('data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.4241), tensor(2.8215))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train[0][0].min(), ds_train[0][0].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will build a dataloader with a batch size of 64 and 4 workers (number of subprocesses that peform the dataloading). Important: you need to shuffle the training data, not the test data.\n",
    "\n",
    "**NOTE**: if you encounter errors in data loading, try setting `NUM_WORKERS = 0` temporarily to get a more informative error message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 4\n",
    "#########################################################################\n",
    "# TODO: Build a dataloader for both train and test data.\n",
    "#########################################################################\n",
    "\n",
    "# Train dataloader\n",
    "dl_train = DataLoader(dataset=ds_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "# Test dataloader\n",
    "dl_test = DataLoader(dataset=ds_train, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP in Pytorch\n",
    "\n",
    "Next, we will build our customizable model class. We will replicate the model from our last exercises. However, now, we add another variable called `nLayer` that indicates how many hidden linear layers are in your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the parameters to be used\n",
    "nInput = 784 #The input dimension of the first linear layer\n",
    "nOutput = 10 #The output dimension of the last linear layer\n",
    "nLayer = 2 #The number of hidden layers\n",
    "nHidden = 16 #The dimension of the intermediate outputs (output and input dimension of hidden layers)\n",
    "act_fn = nn.ReLU() #Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# TODO: Implement the __init__ of the MLP class. \n",
    "# insert the activation after every linear layer. Important: the number of \n",
    "# hidden layers should be variable!\n",
    "#########################################################################\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, nInput, nOutput, nLayer, nHidden, act_fn):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = [] \n",
    "        \n",
    "        ##### implement this part #####\n",
    "        # Input layer -> Hidden layer\n",
    "        layers.append(nn.Linear(nInput, nHidden))\n",
    "        layers.append(act_fn)\n",
    "\n",
    "        # Hidden layers -> Hidden layers\n",
    "        for _ in range(nLayer-1):\n",
    "            layers.append(nn.Linear(nHidden, nHidden))\n",
    "            layers.append(act_fn)\n",
    "        \n",
    "        # Hidden layers -> Output layer\n",
    "        layers.append(nn.Linear(nHidden, nOutput))\n",
    "\n",
    "        ###############################\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's test if the forward pass works\n",
    "# this should print torch.Size([1, 10])\n",
    "t = torch.randn(1,1,28,28)\n",
    "mlp = MLP(nInput, nOutput, nLayer, nHidden, act_fn)\n",
    "mlp(t).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=16, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=16, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already implemented the test function for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dl_test, device='cpu'):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in dl_test:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(dl_test.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
    "        test_loss, correct, len(dl_test.dataset),\n",
    "        100. * correct / len(dl_test.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you only need to implement the training and you are good to go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# TODO: Implement the missing part of the training function. As a loss function, we want to use cross entropy\n",
    "# It can be called with F.cross_entropy().\n",
    "# Hint: Pass through the model -> Backpropagate gradients -> Take gradient step\n",
    "#########################################################################\n",
    "\n",
    "def train(model, dl_train, optimizer, epoch, log_interval=100, device='cpu'):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(dl_train):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # first we need to zero the gradient, otherwise PyTorch would accumulate them\n",
    "        optimizer.zero_grad()         \n",
    "        \n",
    "        ##### implement this part #####\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        ###############################\n",
    "\n",
    "        # stats\n",
    "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(dl_train.dataset),\n",
    "                100. * batch_idx / len(dl_train), loss.item()))\n",
    "\n",
    "    print('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(\n",
    "        loss.item(), correct, len(dl_train.dataset), # changed loss to loss.item(), since loss is tensor\n",
    "        100. * correct / len(dl_train.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, the setup is almost done. The only missing part is the optimizer. We are going to use Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reinitialize the mlp, so we can play with parameters right here\n",
    "mlp = MLP(nInput, nOutput, nLayer, nHidden, act_fn)\n",
    "optimizer = optim.Adam(mlp.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.330253\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.530279\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.550367\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.423591\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.454173\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.233354\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.221317\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.204452\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.462727\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.153360\n",
      "\n",
      "Train set: Average loss: 0.4058, Accuracy: 51104/60000 (85.2%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.2892, Accuracy: 54940/60000 (91.567%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.181808\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.198142\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.102287\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.292445\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.209039\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.202344\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.176936\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.173684\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.102795\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.276245\n",
      "\n",
      "Train set: Average loss: 0.0771, Accuracy: 55349/60000 (92.2%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.2337, Accuracy: 55905/60000 (93.175%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.165035\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.392936\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.080777\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.210834\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.118996\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.224221\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.339998\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.300329\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.234546\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.102581\n",
      "\n",
      "Train set: Average loss: 0.2772, Accuracy: 56069/60000 (93.4%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.2056, Accuracy: 56315/60000 (93.858%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.193430\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.175567\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.355135\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.116693\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.169790\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.352668\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.308265\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.155756\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.245259\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.280678\n",
      "\n",
      "Train set: Average loss: 0.1113, Accuracy: 56521/60000 (94.2%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.1836, Accuracy: 56690/60000 (94.483%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.162322\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.262737\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.130270\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.208122\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.194878\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.154658\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.275494\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.156097\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.081179\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.224991\n",
      "\n",
      "Train set: Average loss: 0.1486, Accuracy: 56792/60000 (94.7%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.1565, Accuracy: 57208/60000 (95.347%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.206176\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.365318\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.054895\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.195763\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.091665\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.073484\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.373254\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.044970\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.255234\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.080111\n",
      "\n",
      "Train set: Average loss: 0.1505, Accuracy: 57006/60000 (95.0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.1476, Accuracy: 57396/60000 (95.660%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.197940\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.293525\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.367844\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.279753\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.278600\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.142871\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.451967\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.276381\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.287902\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.062486\n",
      "\n",
      "Train set: Average loss: 0.0765, Accuracy: 57172/60000 (95.3%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.1483, Accuracy: 57293/60000 (95.488%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.255406\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.135098\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.157557\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.138779\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.084589\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.103612\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.101917\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.087258\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.180715\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.045140\n",
      "\n",
      "Train set: Average loss: 0.0132, Accuracy: 57278/60000 (95.5%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.1323, Accuracy: 57645/60000 (96.075%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.149319\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.155440\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.167323\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.145623\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.036843\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.151469\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.101140\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.194866\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.158470\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.229691\n",
      "\n",
      "Train set: Average loss: 0.0758, Accuracy: 57413/60000 (95.7%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.1340, Accuracy: 57585/60000 (95.975%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.127122\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.189178\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.103080\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.080012\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.071387\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.051057\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.148085\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.138837\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.179066\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.404147\n",
      "\n",
      "Train set: Average loss: 0.0383, Accuracy: 57533/60000 (95.9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.1279, Accuracy: 57648/60000 (96.080%)\n",
      "\n",
      "Training is finished.\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(mlp, dl_train, optimizer, epoch, log_interval=100)\n",
    "    test(mlp, dl_test)\n",
    "\n",
    "print ('Training is finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, you should see test accuracies of > **94%** - Can you do some parameter tuning (e.g. increasing the number of layers or hidden dimension) to boost the test accuracy to > **97%**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.275732\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.839967\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.218795\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.212569\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.346788\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.092915\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.188334\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.296922\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.405609\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.242276\n",
      "\n",
      "Train set: Average loss: 0.2570, Accuracy: 53664/60000 (89.4%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.1981, Accuracy: 56476/60000 (94.127%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.173846\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.309749\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.128486\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.072014\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.232209\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.130336\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.127055\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.229234\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.128212\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.194602\n",
      "\n",
      "Train set: Average loss: 0.1530, Accuracy: 56848/60000 (94.7%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.1330, Accuracy: 57591/60000 (95.985%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.244725\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.216422\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.077163\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.379414\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.232478\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.049342\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.062699\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.212623\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.083802\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.171785\n",
      "\n",
      "Train set: Average loss: 0.1546, Accuracy: 57542/60000 (95.9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.1142, Accuracy: 57938/60000 (96.563%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.070720\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.073326\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.046156\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.038510\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.052062\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.120745\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.074614\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.150567\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.026832\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.081524\n",
      "\n",
      "Train set: Average loss: 0.1321, Accuracy: 57957/60000 (96.6%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0906, Accuracy: 58401/60000 (97.335%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.022019\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.074702\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.031568\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.033327\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.115153\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.067927\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.131839\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.085834\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.068209\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.162324\n",
      "\n",
      "Train set: Average loss: 0.1030, Accuracy: 58196/60000 (97.0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0806, Accuracy: 58556/60000 (97.593%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.136518\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.127945\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.024012\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.068278\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.117919\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.108684\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.045854\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.031181\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.151518\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.253725\n",
      "\n",
      "Train set: Average loss: 0.0481, Accuracy: 58338/60000 (97.2%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0746, Accuracy: 58669/60000 (97.782%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.108592\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.043835\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.039831\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.037536\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.058644\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.043492\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.071294\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.076081\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.024175\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.093065\n",
      "\n",
      "Train set: Average loss: 0.1077, Accuracy: 58497/60000 (97.5%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0675, Accuracy: 58763/60000 (97.938%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.035353\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.143962\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.064472\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.094950\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.025752\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.132907\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.086602\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.037793\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.194658\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.062281\n",
      "\n",
      "Train set: Average loss: 0.1156, Accuracy: 58647/60000 (97.7%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0596, Accuracy: 58888/60000 (98.147%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.194009\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.035512\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.004974\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.071626\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.016920\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.102274\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.085979\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.168402\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.035424\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.131562\n",
      "\n",
      "Train set: Average loss: 0.2713, Accuracy: 58733/60000 (97.9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0549, Accuracy: 58975/60000 (98.292%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.062556\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.132403\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.112798\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.026228\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.063938\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.024834\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.035340\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.057433\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.101689\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.017691\n",
      "\n",
      "Train set: Average loss: 0.1449, Accuracy: 58783/60000 (98.0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0580, Accuracy: 58868/60000 (98.113%)\n",
      "\n",
      "Training is finished.\n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "#TODO: modify the parameters below to see which setting that you can get to 97%\n",
    "#########################################################################\n",
    "nLayer = 2 # change +1 did not imrpove by a lot... not worth it here\n",
    "nHidden = 32 # *2 +1 did improve!\n",
    "act_fn = nn.ReLU()\n",
    "\n",
    "# reinitialize the mlp, so we can play with parameters right here\n",
    "mlp = MLP(nInput, nOutput, nLayer, nHidden, act_fn)\n",
    "optimizer = optim.Adam(mlp.parameters())\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(mlp, dl_train, optimizer, epoch, log_interval=100)\n",
    "    test(mlp, dl_test)\n",
    "\n",
    "print ('Training is finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you move on to the next exercise, you can further play with the other parameters (learning rate, epochs, a different optimizer, etc.) to get a feeling what can improve or hamper performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "Alright, we matched our prior performance. Let's surpass it! You will soon see the power of CNN by building a small one yourself. The structure should be as follows\n",
    "\n",
    "\n",
    "\n",
    "<table>\n",
    "  <tr><th>CNN Architecture</th></tr>\n",
    "  <tr><td>Conv2d: <code>C<sub>in</sub>=1</code>, <code>C<sub>out</sub>=32</code>, <code>K=3</code>, <code>S=1</code>, <code>P=0</code></td></tr>\n",
    "  <tr><td>ReLU</td></tr>\n",
    "  <tr><td>Conv2d: <code>C<sub>in</sub>=32</code>, <code>C<sub>out</sub>=64</code>, <code>K=3</code>, <code>S=1</code>, <code>P=0</code></td></tr>\n",
    "  <tr><td>ReLU</td></tr>\n",
    "  <tr><td>MaxPool2d: <code>K=2</code>, <code>S=2</code>, <code>P=0</code></td></tr>\n",
    "  <tr><td>Dropout: <code>p=0.25</code></td></tr>\n",
    "  <tr><td>Linear: <code>C<sub>in</sub>=9216</code>, <code>C<sub>out</sub>=128</code></td></tr>\n",
    "  <tr><td>ReLU</td></tr>\n",
    "  <tr><td>Dropout: <code>p=0.5</code></td></tr>\n",
    "  <tr><td>Linear: <code>C<sub>in</sub>=128</code>, <code>C<sub>out</sub>=10</code></td></tr>\n",
    "</table>\n",
    "\n",
    "The layers you will need are: \n",
    "\n",
    "`nn.Conv2d,  nn.Linear,  nn.Dropout, nn.MaxPool2d, nn.Flatten`\n",
    "\n",
    "See https://docs.pytorch.org/docs/stable/nn.html for a full description of different layers. For layers without parameters you can alternatively use these functions in the forward pass:  \n",
    "\n",
    "`F.max_pool2d, torch.flatten`\n",
    "\n",
    "The effect is the same - the layers  `nn.MaxPool2d` and `nn.Flatten` are simple wrappers around those functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# TODO: Implement the __init__ and forward method of the CNN class. \n",
    "# Hint: do not forget to flatten the appropriate dimensions after the convolutional blocks. \n",
    "# A linear layers expects input of the shape (N, F) with batch size N and feature size F \n",
    "# whereas convolutional layers produce outputs of shape (N, C, H, W) with batch size N, \n",
    "# number of output channels C, output height H and output width W.\n",
    "#########################################################################\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.drop1 = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.drop2 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.drop1(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop2(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's test if the forward pass works\n",
    "# this should print torch.Size([1, 10])\n",
    "t = torch.randn(1,1,28,28)\n",
    "cnn = CNN()\n",
    "cnn(t).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, let's train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(cnn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.293362\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.264801\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.158314\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.187809\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.066994\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.202992\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.114826\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.270030\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.097608\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.070724\n",
      "\n",
      "Train set: Average loss: 0.0508, Accuracy: 56430/60000 (94.0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0422, Accuracy: 59216/60000 (98.693%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.060346\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.058021\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.070655\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.125169\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.116533\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.072721\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.030192\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.130287\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.042200\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.034473\n",
      "\n",
      "Train set: Average loss: 0.0245, Accuracy: 58495/60000 (97.5%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0281, Accuracy: 59480/60000 (99.133%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.060668\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.028057\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.034506\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.225886\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.089585\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.009454\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.040078\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.095290\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.023181\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.139798\n",
      "\n",
      "Train set: Average loss: 0.1110, Accuracy: 58886/60000 (98.1%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0191, Accuracy: 59653/60000 (99.422%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.030144\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.019438\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.035581\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.042004\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.049003\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.114756\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.031200\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.021498\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.008596\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.012068\n",
      "\n",
      "Train set: Average loss: 0.0206, Accuracy: 59014/60000 (98.4%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0134, Accuracy: 59756/60000 (99.593%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.006796\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.052342\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.024382\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.003197\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.145293\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.003584\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.078752\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.029327\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.075629\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.116807\n",
      "\n",
      "Train set: Average loss: 0.0055, Accuracy: 59164/60000 (98.6%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0124, Accuracy: 59782/60000 (99.637%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(cnn, dl_train, optimizer, epoch, log_interval=100)\n",
    "    test(cnn, dl_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will probably take a bit longer to train, as a convolutional network is not very efficient on a CPU. The current settings should get you around **99%** accuracy. Nice! \n",
    "Again, you should try different hyperparameters and see how far you can push the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inline Question\n",
    "\n",
    "If your model weight is randomly initalized, and no training is done as above. What accuracy do you think the model will get for a 10-class classification task in theory?\n",
    "\n",
    "**Your answer**: When the weights are random initalized and we don't train, the predictions are also random over the classes. So the expected accuracy is 1/10 (10%).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on CIFAR10\n",
    "\n",
    "Now we are going to move to something more challenging - CIFAR10. We can reuse most of the code above. Thankfully, CIFAR is also a popular dataset, so we can again make use of a PyTorch convience function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = datasets.CIFAR10(root='./data', train=True, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous exercise, the dataset is not normalized yet, so we need to calculate the normalization constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims_train = torch.tensor(ds_train.data)\n",
    "ims_train = ims_train.float() / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2470, 0.2435, 0.2616])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ims_train.std((0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# TODO: calculate the mean and std of CIFAR\n",
    "# hint: We want the mean and std of the channel dimension, these should\n",
    "# be 3 dimensional\n",
    "#########################################################################\n",
    "mu = torch.mean(ims_train, dim=(0, 1, 2))\n",
    "std = torch.std(ims_train, dim=(0, 1, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4914, 0.4822, 0.4465])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(ims_train, dim=(0,1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For CIFAR we want to additionally apply some data augmentation transforms to the samples in our dataset for improved generalization. You can find a comprehensive overview of available transforms under the following link.\n",
    "\n",
    "https://docs.pytorch.org/vision/0.8/transforms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "NUM_WORKERS = 0 # if you encounter some unexpected errors in data loading, try setting `NUM_WORKERS = 0`\n",
    "#########################################################################\n",
    "# TODO: Implement the proper transforms for the training and test dataloaders. \n",
    "# Then build train and test dataloaders with batch size 128 and 4 workers\n",
    "#\n",
    "# These are the transforms that should be applied.\n",
    "# Train: \n",
    "# - Apply a random crop with size 32 on a padded version of the image with P=4\n",
    "# - Flip the image horizontally with a probability of 40 %\n",
    "# - Transform to a Tensor\n",
    "# - Normalize with the constants calculated above\n",
    "# Test: \n",
    "# - Transform to a Tensor\n",
    "# - Normalize with the constants calculated above\n",
    "#########################################################################\n",
    "\n",
    "# Transform train\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(p=0.4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mu, std)\n",
    "])\n",
    "\n",
    "# Transform test\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mu, std)\n",
    "])\n",
    "\n",
    "ds_train = datasets.CIFAR10('./data', train=True, download=True, transform=transform_train)\n",
    "ds_test = datasets.CIFAR10('./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "dl_train = DataLoader(dataset=ds_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "dl_test = DataLoader(dataset=ds_test, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the  optimizer, this time we use stochastic gradient descent (SGD). The scheduler adapts the learning rate during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN()\n",
    "optimizer = optim.SGD(cnn.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 1, 3, 3], expected input[128, 3, 32, 32] to have 1 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     test(cnn, dl_test)    \n\u001b[1;32m      5\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[28], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dl_train, optimizer, epoch, log_interval, device)\u001b[0m\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()         \n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m##### implement this part #####\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(output, target)\n\u001b[1;32m     19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/cv-lab3/lib/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cv-lab3/lib/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[48], line 23\u001b[0m, in \u001b[0;36mCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 23\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     25\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x))\n\u001b[1;32m     26\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/cv-lab3/lib/python3.9/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cv-lab3/lib/python3.9/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/cv-lab3/lib/python3.9/site-packages/torch/nn/modules/conv.py:548\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cv-lab3/lib/python3.9/site-packages/torch/nn/modules/conv.py:543\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    533\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    534\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    542\u001b[0m     )\n\u001b[0;32m--> 543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 1, 3, 3], expected input[128, 3, 32, 32] to have 1 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(cnn, dl_train, optimizer, epoch, log_interval=100)\n",
    "    test(cnn, dl_test)    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will not work. You should see the following error message\n",
    "\n",
    "```\n",
    "Given groups=1, weight of size [32, 1, 3, 3], expected input[128, 3, 32, 32] to have 1 channels, but got 3 channels instead\n",
    "```\n",
    "\n",
    "This error is telling us that something is not right in the definition of our model. Copy the CNN class from above and make changes, so the training works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# TODO: Adapt the definition from the CNN class above to work on CIFAR.\n",
    "# You can copy and run the following prompt for evaluation:\n",
    "# CNN()(torch.randn(1,3,32,32)).shape\n",
    "# It should print 'torch.Size([1, 10])'\n",
    "# Hint: You need to change 2 things. \n",
    "#########################################################################\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=0) # changed input channels from 1 to 3\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=0)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.drop1 = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(12544, 128) # changed input features from 9216 to 12544 (64*14*14)\n",
    "        self.drop2 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.drop1(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop2(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.301766\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.931155\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.956576\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.771405\n",
      "\n",
      "Train set: Average loss: 1.8265, Accuracy: 12827/50000 (25.7%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.7363, Accuracy: 3473/10000 (34.730%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.869968\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.999291\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.860697\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.757842\n",
      "\n",
      "Train set: Average loss: 1.5484, Accuracy: 16441/50000 (32.9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.5674, Accuracy: 4073/10000 (40.730%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.877389\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.742516\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.680810\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.734778\n",
      "\n",
      "Train set: Average loss: 1.7301, Accuracy: 18301/50000 (36.6%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.5093, Accuracy: 4566/10000 (45.660%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.740913\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.724946\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.546330\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.707180\n",
      "\n",
      "Train set: Average loss: 1.6572, Accuracy: 18916/50000 (37.8%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.4700, Accuracy: 4626/10000 (46.260%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.534975\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 1.766604\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.615517\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 1.768913\n",
      "\n",
      "Train set: Average loss: 1.7170, Accuracy: 19231/50000 (38.5%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.4894, Accuracy: 4711/10000 (47.110%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.725482\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 1.639141\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 1.841124\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 1.786476\n",
      "\n",
      "Train set: Average loss: 1.7393, Accuracy: 19990/50000 (40.0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.3920, Accuracy: 4915/10000 (49.150%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 1.432756\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 1.812805\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 1.721251\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 1.783506\n",
      "\n",
      "Train set: Average loss: 1.6187, Accuracy: 19962/50000 (39.9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.4168, Accuracy: 4851/10000 (48.510%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 1.586305\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 1.698974\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 1.619509\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 1.447589\n",
      "\n",
      "Train set: Average loss: 1.3782, Accuracy: 20529/50000 (41.1%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.4354, Accuracy: 4787/10000 (47.870%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 1.644587\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 1.621005\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 1.537422\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 1.576663\n",
      "\n",
      "Train set: Average loss: 1.3189, Accuracy: 20834/50000 (41.7%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.3925, Accuracy: 5073/10000 (50.730%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 1.451476\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 1.652254\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 1.577682\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 1.466406\n",
      "\n",
      "Train set: Average loss: 1.6959, Accuracy: 20948/50000 (41.9%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.4691, Accuracy: 4780/10000 (47.800%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "optimizer = optim.SGD(cnn.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(cnn, dl_train, optimizer, epoch, log_interval=100)\n",
    "    test(cnn, dl_test)    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should give 40 - 50 % - and if you are not already on Colab it might cause your laptop to stress out a bit. The performance is a lot better than random, but we can definitely do better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have fun with GPUs (Bonus Exercises)\n",
    "The rest of the exercise is not graded but you can have some fun exploring the capability of these models further. :)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If you didn't already, move to Google Colab. To use a GPU, follow on the collaboratory menu tabs, \"Runtime\" => \"Change runtime type\" and set it to GPU. Then run the same training loop but now on GPU. To do so, we need to explicitly move our tensors to a GPU device - Note that our training loop as define above takes a device parameter as input and alreadt does the job for us.\n",
    "\n",
    "It's as easy as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "if device == 'cuda': torch.backends.cudnn.benchmark = True # additional speed up\n",
    "\n",
    "cnn = CNN()\n",
    "optimizer = optim.SGD(cnn.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "cnn = cnn.to(device)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(cnn, dl_train, optimizer, epoch, log_interval=100, device=device)\n",
    "    test(cnn, dl_test, device=device)    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be way faster now. But the true advantage of the GPU is that we can use much bigger models now and still train them in a reasonable amount of time. PyTorch is again very handy. The torchvision library comes with varies state-of-the-art model architectures, some of which you have seen in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn = resnet18()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks scary! But the only thing you need to change to make it work on CIFAR is the last layer.\n",
    "Currently the last layer is:\n",
    "```\n",
    "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
    "```\n",
    "out_features is the number of classes. This models are developed for Imagenet, a dataset with 1000 classes. So this part of the model you need to adapt. Additionally, you need to add a log-softmax layer again, as we us negative log-likelihood as the training criterion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# TODO: Adapt Resnet to work on CIFAR\n",
    "#########################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should print 'torch.Size([16, 10])'\n",
    "cnn(torch.randn(16,3,32,32)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "if device == 'cuda': torch.backends.cudnn.benchmark = True # this gives us additional speed up\n",
    "\n",
    "optimizer = optim.SGD(cnn.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "cnn = cnn.to(device)\n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(cnn, dl_train, optimizer, epoch, log_interval=100, device=device)\n",
    "    test(cnn, dl_test, device=device)    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should get us well above 75%, the best we got was ~ 80%.\n",
    "\n",
    "If you would like to explore further, you can now use different torchvision architectures, optimizers (Adam is always a good choice), data augmentation techniques, and hyperparameter search to achieve a test accuracy of >90 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-lab3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
